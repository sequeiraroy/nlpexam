{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1114dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "message = [\"Shaw likes to play cricket\",\n",
    "          \"Mary likes to play tennis\",\n",
    "          \"John likes to play volleyball or cricket\",\n",
    "           \"Heena likes to play tennis or throwball\"]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "vec.fit(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa0f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words are: ['cricket' 'heena' 'john' 'likes' 'mary' 'or' 'play' 'shaw' 'tennis'\n",
      " 'throwball' 'to' 'volleyball']\n"
     ]
    }
   ],
   "source": [
    "transform_message = vec.transform(message)\n",
    "print(\"Unique words are:\", vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e955117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11\n",
       "0   1   0   0   1   0   0   1   1   0   0   1   0\n",
       "1   0   0   0   1   1   0   1   0   1   0   1   0\n",
       "2   1   0   1   1   0   1   1   0   0   0   1   1\n",
       "3   0   1   0   1   0   1   1   0   1   1   1   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(transform_message.toarray())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3e84f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cricket</th>\n",
       "      <th>heena</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>or</th>\n",
       "      <th>play</th>\n",
       "      <th>shaw</th>\n",
       "      <th>tennis</th>\n",
       "      <th>throwball</th>\n",
       "      <th>to</th>\n",
       "      <th>volleyball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cricket  heena  john  likes  mary  or  play  shaw  tennis  throwball  to  \\\n",
       "0        1      0     0      1     0   0     1     1       0          0   1   \n",
       "1        0      0     0      1     1   0     1     0       1          0   1   \n",
       "2        1      0     1      1     0   1     1     0       0          0   1   \n",
       "3        0      1     0      1     0   1     1     0       1          1   1   \n",
       "\n",
       "   volleyball  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = vec.get_feature_names_out()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e5bc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqure features : ['cricket' 'heena' 'john' 'likes' 'mary' 'or' 'play' 'shaw' 'tennis'\n",
      " 'throwball' 'to' 'volleyball']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "transform_message = vec.fit_transform(message)\n",
    "feature_names = vec.get_feature_names_out()\n",
    "print(\"Uniqure features :\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "261e0505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.50487895, 0.        , 0.        , 0.3341742 , 0.        ,\n",
       "         0.        , 0.3341742 , 0.64037493, 0.        , 0.        ,\n",
       "         0.3341742 , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.3341742 , 0.64037493,\n",
       "         0.        , 0.3341742 , 0.        , 0.50487895, 0.        ,\n",
       "         0.3341742 , 0.        ],\n",
       "        [0.39127526, 0.        , 0.49628305, 0.25898108, 0.        ,\n",
       "         0.39127526, 0.25898108, 0.        , 0.        , 0.        ,\n",
       "         0.25898108, 0.49628305],\n",
       "        [0.        , 0.49628305, 0.        , 0.25898108, 0.        ,\n",
       "         0.39127526, 0.25898108, 0.        , 0.39127526, 0.49628305,\n",
       "         0.25898108, 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = transform_message.todense()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d29318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5048789499185483,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3341742038105307,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3341742038105307,\n",
       "  0.6403749295935449,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3341742038105307,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3341742038105307,\n",
       "  0.6403749295935449,\n",
       "  0.0,\n",
       "  0.3341742038105307,\n",
       "  0.0,\n",
       "  0.5048789499185483,\n",
       "  0.0,\n",
       "  0.3341742038105307,\n",
       "  0.0],\n",
       " [0.39127525900506077,\n",
       "  0.0,\n",
       "  0.49628305255642946,\n",
       "  0.25898108481225013,\n",
       "  0.0,\n",
       "  0.39127525900506077,\n",
       "  0.25898108481225013,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.25898108481225013,\n",
       "  0.49628305255642946],\n",
       " [0.0,\n",
       "  0.49628305255642946,\n",
       "  0.0,\n",
       "  0.25898108481225013,\n",
       "  0.0,\n",
       "  0.39127525900506077,\n",
       "  0.25898108481225013,\n",
       "  0.0,\n",
       "  0.39127525900506077,\n",
       "  0.49628305255642946,\n",
       "  0.25898108481225013,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denselist = matrix.tolist()\n",
    "denselist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b977f344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cricket</th>\n",
       "      <th>heena</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>or</th>\n",
       "      <th>play</th>\n",
       "      <th>shaw</th>\n",
       "      <th>tennis</th>\n",
       "      <th>throwball</th>\n",
       "      <th>to</th>\n",
       "      <th>volleyball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496283</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>0.496283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.496283</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cricket     heena      john     likes      mary        or      play  \\\n",
       "0  0.504879  0.000000  0.000000  0.334174  0.000000  0.000000  0.334174   \n",
       "1  0.000000  0.000000  0.000000  0.334174  0.640375  0.000000  0.334174   \n",
       "2  0.391275  0.000000  0.496283  0.258981  0.000000  0.391275  0.258981   \n",
       "3  0.000000  0.496283  0.000000  0.258981  0.000000  0.391275  0.258981   \n",
       "\n",
       "       shaw    tennis  throwball        to  volleyball  \n",
       "0  0.640375  0.000000   0.000000  0.334174    0.000000  \n",
       "1  0.000000  0.504879   0.000000  0.334174    0.000000  \n",
       "2  0.000000  0.000000   0.000000  0.258981    0.496283  \n",
       "3  0.000000  0.391275   0.496283  0.258981    0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(denselist, columns = feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66713560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['With Bag of Words and TF-IDF text vectorization techniques we did not get semantic meaning of words But for most of the applications of NLP tasks like sentiment classification, sarcasm detection etc require semantic meaning of a word and semantic relationships of a word with other words.\\n',\n",
       " 'Word embeddings captures semantic and syntactic relationships between words and also the context of words in a document. \\n',\n",
       " 'Word2vec technique used to implement word embeddings.\\n',\n",
       " 'Word2vec model takes input as a large size of corpus and produces output to vector space. \\n',\n",
       " 'This vector space size may be in hundred of dimensionality. \\n',\n",
       " 'Each word vector will be placed on this vector space. \\n',\n",
       " 'In vector space words that share context commonly in a corpus are closer to each other. \\n',\n",
       " 'Word vector having positions of corresponding words in a vector space.\\n',\n",
       " 'Word2vec models predict the context words of a center word using skip-gram method. \\n',\n",
       " 'Skip-gram works well with a small dataset and identifies rare words really well and CBow is just a reverse method of the skip gram method.\\n',\n",
       " 'Here we are taking context words as input and predicting the center word within the window and another difference from skip gram method is, It was working faster and better representations for most frequency words.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "with open(\"word2vec.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    sentences = f.readlines()\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03658cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence :  With Bag of Words and TF-IDF text vectorization techniques we did not get semantic meaning of words But for most of the applications of NLP tasks like sentiment classification, sarcasm detection etc require semantic meaning of a word and semantic relationships of a word with other words.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First sentence : \", sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20fdc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range (len(sentences)):\n",
    "    sentences[i] = re.sub(\"[^a-zA-Z]\", \" \", str(sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330d79e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentences:  11\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of sentences: \", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5857bbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With Bag of Words and TF IDF text vectorization techniques we did not get semantic meaning of words But for most of the applications of NLP tasks like sentiment classification  sarcasm detection etc require semantic meaning of a word and semantic relationships of a word with other words  '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56f66314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence:  ['With', 'Bag', 'of', 'Words', 'and', 'TF', 'IDF', 'text', 'vectorization', 'techniques', 'we', 'did', 'not', 'get', 'semantic', 'meaning', 'of', 'words', 'But', 'for', 'most', 'of', 'the', 'applications', 'of', 'NLP', 'tasks', 'like', 'sentiment', 'classification', 'sarcasm', 'detection', 'etc', 'require', 'semantic', 'meaning', 'of', 'a', 'word', 'and', 'semantic', 'relationships', 'of', 'a', 'word', 'with', 'other', 'words']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = []\n",
    "for sent in sentences:\n",
    "    word_tokens.append(word_tokenize(sent))\n",
    "    \n",
    "print(\"Tokenized sentence: \", word_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "733ffbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = Word2Vec( sentences = word_tokens,\n",
    "                       vector_size = 2,\n",
    "                       window = 2,\n",
    "                       min_count = 2,\n",
    "                       workers = 1,\n",
    "                       sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a51d9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of',\n",
       " 'and',\n",
       " 'words',\n",
       " 'a',\n",
       " 'vector',\n",
       " 'the',\n",
       " 'word',\n",
       " 'space',\n",
       " 'Word',\n",
       " 'in',\n",
       " 'semantic',\n",
       " 'context',\n",
       " 'method',\n",
       " 'gram',\n",
       " 'to',\n",
       " 'vec',\n",
       " 'skip',\n",
       " 'as',\n",
       " 'are',\n",
       " 'we',\n",
       " 'meaning',\n",
       " 'for',\n",
       " 'most',\n",
       " 'center',\n",
       " 'be',\n",
       " 'input',\n",
       " 'relationships',\n",
       " 'with',\n",
       " 'other',\n",
       " 'corpus',\n",
       " 'embeddings',\n",
       " 'well',\n",
       " 'size',\n",
       " 'is']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_cbow = list(model_cbow.wv.index_to_key)\n",
    "words_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b823646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words:  34\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words: \", len(words_cbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c38aac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25310904, 0.45070305], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get word embeddings:\n",
    "model_cbow.wv.__getitem__('and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9d46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
