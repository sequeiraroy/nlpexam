{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f397dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing refers to the branch of\n",
      "computer science and more specifically the branch of \n",
      "artificial intelligence, concerned with giving computers\n",
      "the ability to understand text and spoken words in much \n",
      "the same way human beings can. Human language is filled with\n",
      "ambiguities that make it incredibly difficult to write software\n",
      "that accurately determines the intended meaning of text or voice\n",
      "data. Homonyms, homophones,sarcasm, idioms, metaphors, grammar\n",
      "and usage exceptions,variations in sentence structure. These\n",
      "just a few of the irregularities of human language that take\n",
      "humans years to learn, but that programmers must teach natural\n",
      "language driven applications to recognize and understand \n",
      "accurately from the start if those applications are going to be\n",
      "useful.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"StemLem.txt\")\n",
    "text = f.read()\n",
    "print(text)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54eff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  --->  natur\n",
      "language  --->  languag\n",
      "processing  --->  process\n",
      "refers  --->  refer\n",
      "to  --->  to\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "computer  --->  comput\n",
      "science  --->  scienc\n",
      "and  --->  and\n",
      "more  --->  more\n",
      "specifically  --->  specif\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "artificial  --->  artifici\n",
      "intelligence  --->  intellig\n",
      ",  --->  ,\n",
      "concerned  --->  concern\n",
      "with  --->  with\n",
      "giving  --->  give\n",
      "computers  --->  comput\n",
      "the  --->  the\n",
      "ability  --->  abil\n",
      "to  --->  to\n",
      "understand  --->  understand\n",
      "text  --->  text\n",
      "and  --->  and\n",
      "spoken  --->  spoken\n",
      "words  --->  word\n",
      "in  --->  in\n",
      "much  --->  much\n",
      "the  --->  the\n",
      "same  --->  same\n",
      "way  --->  way\n",
      "human  --->  human\n",
      "beings  --->  be\n",
      "can  --->  can\n",
      ".  --->  .\n",
      "Human  --->  human\n",
      "language  --->  languag\n",
      "is  --->  is\n",
      "filled  --->  fill\n",
      "with  --->  with\n",
      "ambiguities  --->  ambigu\n",
      "that  --->  that\n",
      "make  --->  make\n",
      "it  --->  it\n",
      "incredibly  --->  incred\n",
      "difficult  --->  difficult\n",
      "to  --->  to\n",
      "write  --->  write\n",
      "software  --->  softwar\n",
      "that  --->  that\n",
      "accurately  --->  accur\n",
      "determines  --->  determin\n",
      "the  --->  the\n",
      "intended  --->  intend\n",
      "meaning  --->  mean\n",
      "of  --->  of\n",
      "text  --->  text\n",
      "or  --->  or\n",
      "voice  --->  voic\n",
      "data  --->  data\n",
      ".  --->  .\n",
      "Homonyms  --->  homonym\n",
      ",  --->  ,\n",
      "homophones  --->  homophon\n",
      ",  --->  ,\n",
      "sarcasm  --->  sarcasm\n",
      ",  --->  ,\n",
      "idioms  --->  idiom\n",
      ",  --->  ,\n",
      "metaphors  --->  metaphor\n",
      ",  --->  ,\n",
      "grammar  --->  grammar\n",
      "and  --->  and\n",
      "usage  --->  usag\n",
      "exceptions  --->  except\n",
      ",  --->  ,\n",
      "variations  --->  variat\n",
      "in  --->  in\n",
      "sentence  --->  sentenc\n",
      "structure  --->  structur\n",
      ".  --->  .\n",
      "These  --->  these\n",
      "just  --->  just\n",
      "a  --->  a\n",
      "few  --->  few\n",
      "of  --->  of\n",
      "the  --->  the\n",
      "irregularities  --->  irregular\n",
      "of  --->  of\n",
      "human  --->  human\n",
      "language  --->  languag\n",
      "that  --->  that\n",
      "take  --->  take\n",
      "humans  --->  human\n",
      "years  --->  year\n",
      "to  --->  to\n",
      "learn  --->  learn\n",
      ",  --->  ,\n",
      "but  --->  but\n",
      "that  --->  that\n",
      "programmers  --->  programm\n",
      "must  --->  must\n",
      "teach  --->  teach\n",
      "natural  --->  natur\n",
      "language  --->  languag\n",
      "driven  --->  driven\n",
      "applications  --->  applic\n",
      "to  --->  to\n",
      "recognize  --->  recogn\n",
      "and  --->  and\n",
      "understand  --->  understand\n",
      "accurately  --->  accur\n",
      "from  --->  from\n",
      "the  --->  the\n",
      "start  --->  start\n",
      "if  --->  if\n",
      "those  --->  those\n",
      "applications  --->  applic\n",
      "are  --->  are\n",
      "going  --->  go\n",
      "to  --->  to\n",
      "be  --->  be\n",
      "useful  --->  use\n",
      ".  --->  .\n"
     ]
    }
   ],
   "source": [
    "# PorterStemmer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" ---> \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b61262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  --->  natur\n",
      "language  --->  languag\n",
      "processing  --->  process\n",
      "refers  --->  refer\n",
      "to  --->  to\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "computer  --->  comput\n",
      "science  --->  scienc\n",
      "and  --->  and\n",
      "more  --->  more\n",
      "specifically  --->  specif\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "artificial  --->  artifici\n",
      "intelligence  --->  intellig\n",
      ",  --->  ,\n",
      "concerned  --->  concern\n",
      "with  --->  with\n",
      "giving  --->  give\n",
      "computers  --->  comput\n",
      "the  --->  the\n",
      "ability  --->  abil\n",
      "to  --->  to\n",
      "understand  --->  understand\n",
      "text  --->  text\n",
      "and  --->  and\n",
      "spoken  --->  spoken\n",
      "words  --->  word\n",
      "in  --->  in\n",
      "much  --->  much\n",
      "the  --->  the\n",
      "same  --->  same\n",
      "way  --->  way\n",
      "human  --->  human\n",
      "beings  --->  be\n",
      "can  --->  can\n",
      ".  --->  .\n",
      "Human  --->  human\n",
      "language  --->  languag\n",
      "is  --->  is\n",
      "filled  --->  fill\n",
      "with  --->  with\n",
      "ambiguities  --->  ambigu\n",
      "that  --->  that\n",
      "make  --->  make\n",
      "it  --->  it\n",
      "incredibly  --->  incred\n",
      "difficult  --->  difficult\n",
      "to  --->  to\n",
      "write  --->  write\n",
      "software  --->  softwar\n",
      "that  --->  that\n",
      "accurately  --->  accur\n",
      "determines  --->  determin\n",
      "the  --->  the\n",
      "intended  --->  intend\n",
      "meaning  --->  mean\n",
      "of  --->  of\n",
      "text  --->  text\n",
      "or  --->  or\n",
      "voice  --->  voic\n",
      "data  --->  data\n",
      ".  --->  .\n",
      "Homonyms  --->  homonym\n",
      ",  --->  ,\n",
      "homophones  --->  homophon\n",
      ",  --->  ,\n",
      "sarcasm  --->  sarcasm\n",
      ",  --->  ,\n",
      "idioms  --->  idiom\n",
      ",  --->  ,\n",
      "metaphors  --->  metaphor\n",
      ",  --->  ,\n",
      "grammar  --->  grammar\n",
      "and  --->  and\n",
      "usage  --->  usag\n",
      "exceptions  --->  except\n",
      ",  --->  ,\n",
      "variations  --->  variat\n",
      "in  --->  in\n",
      "sentence  --->  sentenc\n",
      "structure  --->  structur\n",
      ".  --->  .\n",
      "These  --->  these\n",
      "just  --->  just\n",
      "a  --->  a\n",
      "few  --->  few\n",
      "of  --->  of\n",
      "the  --->  the\n",
      "irregularities  --->  irregular\n",
      "of  --->  of\n",
      "human  --->  human\n",
      "language  --->  languag\n",
      "that  --->  that\n",
      "take  --->  take\n",
      "humans  --->  human\n",
      "years  --->  year\n",
      "to  --->  to\n",
      "learn  --->  learn\n",
      ",  --->  ,\n",
      "but  --->  but\n",
      "that  --->  that\n",
      "programmers  --->  programm\n",
      "must  --->  must\n",
      "teach  --->  teach\n",
      "natural  --->  natur\n",
      "language  --->  languag\n",
      "driven  --->  driven\n",
      "applications  --->  applic\n",
      "to  --->  to\n",
      "recognize  --->  recogn\n",
      "and  --->  and\n",
      "understand  --->  understand\n",
      "accurately  --->  accur\n",
      "from  --->  from\n",
      "the  --->  the\n",
      "start  --->  start\n",
      "if  --->  if\n",
      "those  --->  those\n",
      "applications  --->  applic\n",
      "are  --->  are\n",
      "going  --->  go\n",
      "to  --->  to\n",
      "be  --->  be\n",
      "useful  --->  use\n",
      ".  --->  .\n"
     ]
    }
   ],
   "source": [
    "# Snowball Stemmer\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language = 'english')\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" ---> \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b1a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  --->  nat\n",
      "language  --->  langu\n",
      "processing  --->  process\n",
      "refers  --->  ref\n",
      "to  --->  to\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "computer  --->  comput\n",
      "science  --->  sci\n",
      "and  --->  and\n",
      "more  --->  mor\n",
      "specifically  --->  spec\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "artificial  --->  art\n",
      "intelligence  --->  intellig\n",
      ",  --->  ,\n",
      "concerned  --->  concern\n",
      "with  --->  with\n",
      "giving  --->  giv\n",
      "computers  --->  comput\n",
      "the  --->  the\n",
      "ability  --->  abl\n",
      "to  --->  to\n",
      "understand  --->  understand\n",
      "text  --->  text\n",
      "and  --->  and\n",
      "spoken  --->  spok\n",
      "words  --->  word\n",
      "in  --->  in\n",
      "much  --->  much\n",
      "the  --->  the\n",
      "same  --->  sam\n",
      "way  --->  way\n",
      "human  --->  hum\n",
      "beings  --->  being\n",
      "can  --->  can\n",
      ".  --->  .\n",
      "Human  --->  hum\n",
      "language  --->  langu\n",
      "is  --->  is\n",
      "filled  --->  fil\n",
      "with  --->  with\n",
      "ambiguities  --->  ambigu\n",
      "that  --->  that\n",
      "make  --->  mak\n",
      "it  --->  it\n",
      "incredibly  --->  incred\n",
      "difficult  --->  difficult\n",
      "to  --->  to\n",
      "write  --->  writ\n",
      "software  --->  softw\n",
      "that  --->  that\n",
      "accurately  --->  acc\n",
      "determines  --->  determin\n",
      "the  --->  the\n",
      "intended  --->  intend\n",
      "meaning  --->  mean\n",
      "of  --->  of\n",
      "text  --->  text\n",
      "or  --->  or\n",
      "voice  --->  voic\n",
      "data  --->  dat\n",
      ".  --->  .\n",
      "Homonyms  --->  homonym\n",
      ",  --->  ,\n",
      "homophones  --->  homophon\n",
      ",  --->  ,\n",
      "sarcasm  --->  sarcasm\n",
      ",  --->  ,\n",
      "idioms  --->  idiom\n",
      ",  --->  ,\n",
      "metaphors  --->  metaph\n",
      ",  --->  ,\n",
      "grammar  --->  gramm\n",
      "and  --->  and\n",
      "usage  --->  us\n",
      "exceptions  --->  exceiv\n",
      ",  --->  ,\n",
      "variations  --->  vary\n",
      "in  --->  in\n",
      "sentence  --->  sent\n",
      "structure  --->  structure\n",
      ".  --->  .\n",
      "These  --->  thes\n",
      "just  --->  just\n",
      "a  --->  a\n",
      "few  --->  few\n",
      "of  --->  of\n",
      "the  --->  the\n",
      "irregularities  --->  irregul\n",
      "of  --->  of\n",
      "human  --->  hum\n",
      "language  --->  langu\n",
      "that  --->  that\n",
      "take  --->  tak\n",
      "humans  --->  hum\n",
      "years  --->  year\n",
      "to  --->  to\n",
      "learn  --->  learn\n",
      ",  --->  ,\n",
      "but  --->  but\n",
      "that  --->  that\n",
      "programmers  --->  program\n",
      "must  --->  must\n",
      "teach  --->  teach\n",
      "natural  --->  nat\n",
      "language  --->  langu\n",
      "driven  --->  driv\n",
      "applications  --->  apply\n",
      "to  --->  to\n",
      "recognize  --->  recogn\n",
      "and  --->  and\n",
      "understand  --->  understand\n",
      "accurately  --->  acc\n",
      "from  --->  from\n",
      "the  --->  the\n",
      "start  --->  start\n",
      "if  --->  if\n",
      "those  --->  thos\n",
      "applications  --->  apply\n",
      "are  --->  ar\n",
      "going  --->  going\n",
      "to  --->  to\n",
      "be  --->  be\n",
      "useful  --->  us\n",
      ".  --->  .\n"
     ]
    }
   ],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" ---> \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5152c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  -->  natural\n",
      "language  -->  language\n",
      "processing  -->  processing\n",
      "refers  -->  refer\n",
      "to  -->  to\n",
      "the  -->  the\n",
      "branch  -->  branch\n",
      "of  -->  of\n",
      "\n",
      "  -->  \n",
      "\n",
      "computer  -->  computer\n",
      "science  -->  science\n",
      "and  -->  and\n",
      "more  -->  more\n",
      "specifically  -->  specifically\n",
      "the  -->  the\n",
      "branch  -->  branch\n",
      "of  -->  of\n",
      "\n",
      "  -->  \n",
      "\n",
      "artificial  -->  artificial\n",
      "intelligence  -->  intelligence\n",
      ",  -->  ,\n",
      "concerned  -->  concern\n",
      "with  -->  with\n",
      "giving  -->  give\n",
      "computers  -->  computer\n",
      "\n",
      "  -->  \n",
      "\n",
      "the  -->  the\n",
      "ability  -->  ability\n",
      "to  -->  to\n",
      "understand  -->  understand\n",
      "text  -->  text\n",
      "and  -->  and\n",
      "spoken  -->  spoken\n",
      "words  -->  word\n",
      "in  -->  in\n",
      "much  -->  much\n",
      "\n",
      "  -->  \n",
      "\n",
      "the  -->  the\n",
      "same  -->  same\n",
      "way  -->  way\n",
      "human  -->  human\n",
      "beings  -->  being\n",
      "can  -->  can\n",
      ".  -->  .\n",
      "Human  -->  human\n",
      "language  -->  language\n",
      "is  -->  be\n",
      "filled  -->  fill\n",
      "with  -->  with\n",
      "\n",
      "  -->  \n",
      "\n",
      "ambiguities  -->  ambiguity\n",
      "that  -->  that\n",
      "make  -->  make\n",
      "it  -->  it\n",
      "incredibly  -->  incredibly\n",
      "difficult  -->  difficult\n",
      "to  -->  to\n",
      "write  -->  write\n",
      "software  -->  software\n",
      "\n",
      "  -->  \n",
      "\n",
      "that  -->  that\n",
      "accurately  -->  accurately\n",
      "determines  -->  determine\n",
      "the  -->  the\n",
      "intended  -->  intend\n",
      "meaning  -->  meaning\n",
      "of  -->  of\n",
      "text  -->  text\n",
      "or  -->  or\n",
      "voice  -->  voice\n",
      "\n",
      "  -->  \n",
      "\n",
      "data  -->  datum\n",
      ".  -->  .\n",
      "Homonyms  -->  Homonyms\n",
      ",  -->  ,\n",
      "homophones  -->  homophone\n",
      ",  -->  ,\n",
      "sarcasm  -->  sarcasm\n",
      ",  -->  ,\n",
      "idioms  -->  idiom\n",
      ",  -->  ,\n",
      "metaphors  -->  metaphor\n",
      ",  -->  ,\n",
      "grammar  -->  grammar\n",
      "\n",
      "  -->  \n",
      "\n",
      "and  -->  and\n",
      "usage  -->  usage\n",
      "exceptions  -->  exception\n",
      ",  -->  ,\n",
      "variations  -->  variation\n",
      "in  -->  in\n",
      "sentence  -->  sentence\n",
      "structure  -->  structure\n",
      ".  -->  .\n",
      "These  -->  these\n",
      "\n",
      "  -->  \n",
      "\n",
      "just  -->  just\n",
      "a  -->  a\n",
      "few  -->  few\n",
      "of  -->  of\n",
      "the  -->  the\n",
      "irregularities  -->  irregularity\n",
      "of  -->  of\n",
      "human  -->  human\n",
      "language  -->  language\n",
      "that  -->  that\n",
      "take  -->  take\n",
      "\n",
      "  -->  \n",
      "\n",
      "humans  -->  human\n",
      "years  -->  year\n",
      "to  -->  to\n",
      "learn  -->  learn\n",
      ",  -->  ,\n",
      "but  -->  but\n",
      "that  -->  that\n",
      "programmers  -->  programmer\n",
      "must  -->  must\n",
      "teach  -->  teach\n",
      "natural  -->  natural\n",
      "\n",
      "  -->  \n",
      "\n",
      "language  -->  language\n",
      "driven  -->  drive\n",
      "applications  -->  application\n",
      "to  -->  to\n",
      "recognize  -->  recognize\n",
      "and  -->  and\n",
      "understand  -->  understand\n",
      "\n",
      "  -->  \n",
      "\n",
      "accurately  -->  accurately\n",
      "from  -->  from\n",
      "the  -->  the\n",
      "start  -->  start\n",
      "if  -->  if\n",
      "those  -->  those\n",
      "applications  -->  application\n",
      "are  -->  be\n",
      "going  -->  go\n",
      "to  -->  to\n",
      "be  -->  be\n",
      "\n",
      "  -->  \n",
      "\n",
      "useful  -->  useful\n",
      ".  -->  .\n"
     ]
    }
   ],
   "source": [
    "# Spacy Lemmatizer\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" --> \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f49e720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  --->  Natural\n",
      "language  --->  language\n",
      "processing  --->  processing\n",
      "refers  --->  refers\n",
      "to  --->  to\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "computer  --->  computer\n",
      "science  --->  science\n",
      "and  --->  and\n",
      "more  --->  more\n",
      "specifically  --->  specifically\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "artificial  --->  artificial\n",
      "intelligence  --->  intelligence\n",
      ",  --->  ,\n",
      "concerned  --->  concerned\n",
      "with  --->  with\n",
      "giving  --->  giving\n",
      "computers  --->  computer\n",
      "the  --->  the\n",
      "ability  --->  ability\n",
      "to  --->  to\n",
      "understand  --->  understand\n",
      "text  --->  text\n",
      "and  --->  and\n",
      "spoken  --->  spoken\n",
      "words  --->  word\n",
      "in  --->  in\n",
      "much  --->  much\n",
      "the  --->  the\n",
      "same  --->  same\n",
      "way  --->  way\n",
      "human  --->  human\n",
      "beings  --->  being\n",
      "can  --->  can\n",
      ".  --->  .\n",
      "Human  --->  Human\n",
      "language  --->  language\n",
      "is  --->  is\n",
      "filled  --->  filled\n",
      "with  --->  with\n",
      "ambiguities  --->  ambiguity\n",
      "that  --->  that\n",
      "make  --->  make\n",
      "it  --->  it\n",
      "incredibly  --->  incredibly\n",
      "difficult  --->  difficult\n",
      "to  --->  to\n",
      "write  --->  write\n",
      "software  --->  software\n",
      "that  --->  that\n",
      "accurately  --->  accurately\n",
      "determines  --->  determines\n",
      "the  --->  the\n",
      "intended  --->  intended\n",
      "meaning  --->  meaning\n",
      "of  --->  of\n",
      "text  --->  text\n",
      "or  --->  or\n",
      "voice  --->  voice\n",
      "data  --->  data\n",
      ".  --->  .\n",
      "Homonyms  --->  Homonyms\n",
      ",  --->  ,\n",
      "homophones  --->  homophone\n",
      ",  --->  ,\n",
      "sarcasm  --->  sarcasm\n",
      ",  --->  ,\n",
      "idioms  --->  idiom\n",
      ",  --->  ,\n",
      "metaphors  --->  metaphor\n",
      ",  --->  ,\n",
      "grammar  --->  grammar\n",
      "and  --->  and\n",
      "usage  --->  usage\n",
      "exceptions  --->  exception\n",
      ",  --->  ,\n",
      "variations  --->  variation\n",
      "in  --->  in\n",
      "sentence  --->  sentence\n",
      "structure  --->  structure\n",
      ".  --->  .\n",
      "These  --->  These\n",
      "just  --->  just\n",
      "a  --->  a\n",
      "few  --->  few\n",
      "of  --->  of\n",
      "the  --->  the\n",
      "irregularities  --->  irregularity\n",
      "of  --->  of\n",
      "human  --->  human\n",
      "language  --->  language\n",
      "that  --->  that\n",
      "take  --->  take\n",
      "humans  --->  human\n",
      "years  --->  year\n",
      "to  --->  to\n",
      "learn  --->  learn\n",
      ",  --->  ,\n",
      "but  --->  but\n",
      "that  --->  that\n",
      "programmers  --->  programmer\n",
      "must  --->  must\n",
      "teach  --->  teach\n",
      "natural  --->  natural\n",
      "language  --->  language\n",
      "driven  --->  driven\n",
      "applications  --->  application\n",
      "to  --->  to\n",
      "recognize  --->  recognize\n",
      "and  --->  and\n",
      "understand  --->  understand\n",
      "accurately  --->  accurately\n",
      "from  --->  from\n",
      "the  --->  the\n",
      "start  --->  start\n",
      "if  --->  if\n",
      "those  --->  those\n",
      "applications  --->  application\n",
      "are  --->  are\n",
      "going  --->  going\n",
      "to  --->  to\n",
      "be  --->  be\n",
      "useful  --->  useful\n",
      ".  --->  .\n"
     ]
    }
   ],
   "source": [
    "# WordNet lemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" ---> \", lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d1cb869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  --->  Natural\n",
      "language  --->  language\n",
      "processing  --->  processing\n",
      "refers  --->  refers\n",
      "to  --->  to\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "computer  --->  computer\n",
      "science  --->  science\n",
      "and  --->  and\n",
      "more  --->  more\n",
      "specifically  --->  specifically\n",
      "the  --->  the\n",
      "branch  --->  branch\n",
      "of  --->  of\n",
      "artificial  --->  artificial\n",
      "intelligence  --->  intelligence\n",
      "concerned  --->  concerned\n",
      "with  --->  with\n",
      "giving  --->  giving\n",
      "computers  --->  computer\n",
      "the  --->  the\n",
      "ability  --->  ability\n",
      "to  --->  to\n",
      "understand  --->  understand\n",
      "text  --->  text\n",
      "and  --->  and\n",
      "spoken  --->  spoken\n",
      "words  --->  word\n",
      "in  --->  in\n",
      "much  --->  much\n",
      "the  --->  the\n",
      "same  --->  same\n",
      "way  --->  way\n",
      "human  --->  human\n",
      "beings  --->  being\n",
      "can  --->  can\n",
      "Human  --->  Human\n",
      "language  --->  language\n",
      "is  --->  is\n",
      "filled  --->  filled\n",
      "with  --->  with\n",
      "ambiguities  --->  ambiguity\n",
      "that  --->  that\n",
      "make  --->  make\n",
      "it  --->  it\n",
      "incredibly  --->  incredibly\n",
      "difficult  --->  difficult\n",
      "to  --->  to\n",
      "write  --->  write\n",
      "software  --->  software\n",
      "that  --->  that\n",
      "accurately  --->  accurately\n",
      "determines  --->  determines\n",
      "the  --->  the\n",
      "intended  --->  intended\n",
      "meaning  --->  meaning\n",
      "of  --->  of\n",
      "text  --->  text\n",
      "or  --->  or\n",
      "voice  --->  voice\n",
      "data  --->  data\n",
      "Homonyms  --->  Homonyms\n",
      "homophones  --->  homophone\n",
      "sarcasm  --->  sarcasm\n",
      "idioms  --->  idiom\n",
      "metaphors  --->  metaphor\n",
      "grammar  --->  grammar\n",
      "and  --->  and\n",
      "usage  --->  usage\n",
      "exceptions  --->  exception\n",
      "variations  --->  variation\n",
      "in  --->  in\n",
      "sentence  --->  sentence\n",
      "structure  --->  structure\n",
      "These  --->  These\n",
      "just  --->  just\n",
      "a  --->  a\n",
      "few  --->  few\n",
      "of  --->  of\n",
      "the  --->  the\n",
      "irregularities  --->  irregularity\n",
      "of  --->  of\n",
      "human  --->  human\n",
      "language  --->  language\n",
      "that  --->  that\n",
      "take  --->  take\n",
      "humans  --->  human\n",
      "years  --->  year\n",
      "to  --->  to\n",
      "learn  --->  learn\n",
      "but  --->  but\n",
      "that  --->  that\n",
      "programmers  --->  programmer\n",
      "must  --->  must\n",
      "teach  --->  teach\n",
      "natural  --->  natural\n",
      "language  --->  language\n",
      "driven  --->  driven\n",
      "applications  --->  application\n",
      "to  --->  to\n",
      "recognize  --->  recognize\n",
      "and  --->  and\n",
      "understand  --->  understand\n",
      "accurately  --->  accurately\n",
      "from  --->  from\n",
      "the  --->  the\n",
      "start  --->  start\n",
      "if  --->  if\n",
      "those  --->  those\n",
      "applications  --->  application\n",
      "are  --->  are\n",
      "going  --->  going\n",
      "to  --->  to\n",
      "be  --->  be\n",
      "useful  --->  useful\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "s = TextBlob(text)\n",
    "\n",
    "for word in s.words:\n",
    "    print(word, \" ---> \", word.lemmatize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1211bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
